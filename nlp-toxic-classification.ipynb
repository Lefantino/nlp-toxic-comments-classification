{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Тестирование</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте обучим модель, которая классифицирует токсичные комментарии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lefantino/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/lefantino/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/lefantino/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/lefantino/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(max(df['text'], key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(min(df['text'], key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете 2 признака:\n",
    "* text - комментарий от пользователя на английском языке, самый длинный комментарий 5000 символов, самый короткий - 5 символов.\n",
    "* target - целевая переменная, метка 0 или 1, характеризующая комментарий как токсичный\n",
    "\n",
    "В самом датасете 159292 строки, нет пропусков, нет дубликатов.  \n",
    "Изучим, что из себя представляют комментарии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1, 'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Ringmail\\nI don't know if he regards himself as an expert, I've sweated enough to know for sure that a broigne is not a victorian mistake, and to find citable sources for it. I understand that the English language wor;ld lacks proper history on the subject, but from a continental point of view, there's no mistake possible that ringmail is different from chainmail and was used in the period between the fall of Rome and the comeback of chainmail in the late 1100s. Also, the high handed way in which he remade all the article with no regard for the effots of those who came before him, and without even setting up an account for people to discuss the matter with him wxas, to my view, qualification for vandalism.\\n\\nI'm quite willing to include the bit about representations making it difficult to differenciate between chainmail and ringmail, and the possibility of misconceptions in the 1800s, but the basic matter as established with my collaboration stands, even if it has to be edited further.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[3000, 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сами комментарии представляют из себя строку, состоящую из предложений или законченных фраз, встречаются так же лишние символы в строках, сокращения, даты, цифры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем комментарии на токены и лемматизируем их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 45s, sys: 43.7 s, total: 13min 29s\n",
      "Wall time: 13min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['lemm_text'] = df.text.apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что получилось:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation Why the edits make under my userna...\n",
       "1    D'aww ! He match this background colour I 'm s...\n",
       "2    Hey man , I 'm really not try to edit war . It...\n",
       "3    `` More I ca n't make any real suggestion on i...\n",
       "4    You , sir , be my hero . Any chance you rememb...\n",
       "Name: lemm_text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemm_text'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же необходимо почистить текст от лишних символов, оставив только слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement = {\n",
    "    \"'m\":\" am\",\n",
    "    \"'v\":\" have\",\n",
    "    \"'re\":\" are\",\n",
    "    \"'ll\":\" will\",\n",
    "    \"'t\":\" not\",\n",
    "}\n",
    "for k,v in replacement.items():\n",
    "    df['lemm_text'] = df['lemm_text'].str.replace(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В идеальном случае необходимо намного тщательнее обработать текст, заменить различные абревиатуры или сленговые сокращения и т.д. Так как проект учебный, не будем заострять на этом внимание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_lemm_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    text = text.strip()\n",
    "    return ' '.join(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemm_text'] = df['lemm_text'].apply(cleaning_lemm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explanation why the edits make under my userna...\n",
       "1    d aww he match this background colour i am see...\n",
       "2    hey man i am really not try to edit war it s j...\n",
       "3    more i ca n not make any real suggestion on im...\n",
       "4    you sir be my hero any chance you remember wha...\n",
       "Name: lemm_text, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemm_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits make under my username hardcore metallica fan be revert they be n not vandalism just closure on some gas after i vote at new york dolls fac and please do n not remove the template from the talk page since i am retire now'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemm_text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобработка текста завершена, разделим данные на обучающую и тестовые выборки. Целевая переменная - toxic, признак - лемматизированный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df['lemm_text']\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, \n",
    "                                                    test_size=0.25, stratify=target, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((119469,), (119469,), (39823,), (39823,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898384\n",
       "1    0.101616\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.8984\n",
       "1    0.1016\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = LogisticRegression(random_state=SEED, penalty='l1', solver='liblinear')\n",
    "model_LGBM = LGBMClassifier(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 40s, sys: 2.76 s, total: 4min 42s\n",
      "Wall time: 4min 43s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words={&#x27;a&#x27;,\n",
       "                                                                    &#x27;about&#x27;,\n",
       "                                                                    &#x27;above&#x27;,\n",
       "                                                                    &#x27;after&#x27;,\n",
       "                                                                    &#x27;again&#x27;,\n",
       "                                                                    &#x27;against&#x27;,\n",
       "                                                                    &#x27;ain&#x27;,\n",
       "                                                                    &#x27;all&#x27;, &#x27;am&#x27;,\n",
       "                                                                    &#x27;an&#x27;, &#x27;and&#x27;,\n",
       "                                                                    &#x27;any&#x27;,\n",
       "                                                                    &#x27;are&#x27;,\n",
       "                                                                    &#x27;aren&#x27;,\n",
       "                                                                    &quot;aren&#x27;t&quot;,\n",
       "                                                                    &#x27;as&#x27;, &#x27;at&#x27;,\n",
       "                                                                    &#x27;be&#x27;,\n",
       "                                                                    &#x27;because&#x27;,\n",
       "                                                                    &#x27;been&#x27;,\n",
       "                                                                    &#x27;before&#x27;,\n",
       "                                                                    &#x27;being&#x27;,\n",
       "                                                                    &#x27;below&#x27;,\n",
       "                                                                    &#x27;between&#x27;,\n",
       "                                                                    &#x27;both&#x27;,\n",
       "                                                                    &#x27;but&#x27;, &#x27;by&#x27;,\n",
       "                                                                    &#x27;can&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t...\n",
       "                                                           solver=&#x27;liblinear&#x27;))]),\n",
       "             param_grid={&#x27;clf__C&#x27;: array([1.00000000e-03, 2.06913808e-03, 4.28133240e-03, 8.85866790e-03,\n",
       "       1.83298071e-02, 3.79269019e-02, 7.84759970e-02, 1.62377674e-01,\n",
       "       3.35981829e-01, 6.95192796e-01, 1.43844989e+00, 2.97635144e+00,\n",
       "       6.15848211e+00, 1.27427499e+01, 2.63665090e+01, 5.45559478e+01,\n",
       "       1.12883789e+02, 2.33572147e+02, 4.83293024e+02, 1.00000000e+03])},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words={&#x27;a&#x27;,\n",
       "                                                                    &#x27;about&#x27;,\n",
       "                                                                    &#x27;above&#x27;,\n",
       "                                                                    &#x27;after&#x27;,\n",
       "                                                                    &#x27;again&#x27;,\n",
       "                                                                    &#x27;against&#x27;,\n",
       "                                                                    &#x27;ain&#x27;,\n",
       "                                                                    &#x27;all&#x27;, &#x27;am&#x27;,\n",
       "                                                                    &#x27;an&#x27;, &#x27;and&#x27;,\n",
       "                                                                    &#x27;any&#x27;,\n",
       "                                                                    &#x27;are&#x27;,\n",
       "                                                                    &#x27;aren&#x27;,\n",
       "                                                                    &quot;aren&#x27;t&quot;,\n",
       "                                                                    &#x27;as&#x27;, &#x27;at&#x27;,\n",
       "                                                                    &#x27;be&#x27;,\n",
       "                                                                    &#x27;because&#x27;,\n",
       "                                                                    &#x27;been&#x27;,\n",
       "                                                                    &#x27;before&#x27;,\n",
       "                                                                    &#x27;being&#x27;,\n",
       "                                                                    &#x27;below&#x27;,\n",
       "                                                                    &#x27;between&#x27;,\n",
       "                                                                    &#x27;both&#x27;,\n",
       "                                                                    &#x27;but&#x27;, &#x27;by&#x27;,\n",
       "                                                                    &#x27;can&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t...\n",
       "                                                           solver=&#x27;liblinear&#x27;))]),\n",
       "             param_grid={&#x27;clf__C&#x27;: array([1.00000000e-03, 2.06913808e-03, 4.28133240e-03, 8.85866790e-03,\n",
       "       1.83298071e-02, 3.79269019e-02, 7.84759970e-02, 1.62377674e-01,\n",
       "       3.35981829e-01, 6.95192796e-01, 1.43844989e+00, 2.97635144e+00,\n",
       "       6.15848211e+00, 1.27427499e+01, 2.63665090e+01, 5.45559478e+01,\n",
       "       1.12883789e+02, 2.33572147e+02, 4.83293024e+02, 1.00000000e+03])},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 LogisticRegression(penalty=&#x27;l1&#x27;, random_state=42,\n",
       "                                    solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                            &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                            &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                            &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words={'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'ain',\n",
       "                                                                    'all', 'am',\n",
       "                                                                    'an', 'and',\n",
       "                                                                    'any',\n",
       "                                                                    'are',\n",
       "                                                                    'aren',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'as', 'at',\n",
       "                                                                    'be',\n",
       "                                                                    'because',\n",
       "                                                                    'been',\n",
       "                                                                    'before',\n",
       "                                                                    'being',\n",
       "                                                                    'below',\n",
       "                                                                    'between',\n",
       "                                                                    'both',\n",
       "                                                                    'but', 'by',\n",
       "                                                                    'can',\n",
       "                                                                    'couldn',\n",
       "                                                                    \"couldn't...\n",
       "                                                           solver='liblinear'))]),\n",
       "             param_grid={'clf__C': array([1.00000000e-03, 2.06913808e-03, 4.28133240e-03, 8.85866790e-03,\n",
       "       1.83298071e-02, 3.79269019e-02, 7.84759970e-02, 1.62377674e-01,\n",
       "       3.35981829e-01, 6.95192796e-01, 1.43844989e+00, 2.97635144e+00,\n",
       "       6.15848211e+00, 1.27427499e+01, 2.63665090e+01, 5.45559478e+01,\n",
       "       1.12883789e+02, 2.33572147e+02, 4.83293024e+02, 1.00000000e+03])},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('clf', model_LR)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'clf__C':np.logspace(-3,3,20)\n",
    "}\n",
    "\n",
    "grid_LR = GridSearchCV(pipe, param_grid = params, scoring='f1', cv=cv)\n",
    "grid_LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'am', 'an', 'and', 'any', 'are',\n",
      "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', 'been', 'before',\n",
      "                                             'being', 'below', 'between',\n",
      "                                             'both', 'but', 'by', 'can',\n",
      "                                             'couldn', \"couldn't\", ...})),\n",
      "                ('clf',\n",
      "                 LogisticRegression(C=2.976351441631316, penalty='l1',\n",
      "                                    random_state=42, solver='liblinear'))])\n",
      "0.7795868701397487\n"
     ]
    }
   ],
   "source": [
    "print(grid_LR.best_estimator_)\n",
    "print(grid_LR.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 58min 6s, sys: 5min 24s, total: 1h 3min 30s\n",
      "Wall time: 10min 51s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words={&#x27;a&#x27;,\n",
       "                                                                    &#x27;about&#x27;,\n",
       "                                                                    &#x27;above&#x27;,\n",
       "                                                                    &#x27;after&#x27;,\n",
       "                                                                    &#x27;again&#x27;,\n",
       "                                                                    &#x27;against&#x27;,\n",
       "                                                                    &#x27;ain&#x27;,\n",
       "                                                                    &#x27;all&#x27;, &#x27;am&#x27;,\n",
       "                                                                    &#x27;an&#x27;, &#x27;and&#x27;,\n",
       "                                                                    &#x27;any&#x27;,\n",
       "                                                                    &#x27;are&#x27;,\n",
       "                                                                    &#x27;aren&#x27;,\n",
       "                                                                    &quot;aren&#x27;t&quot;,\n",
       "                                                                    &#x27;as&#x27;, &#x27;at&#x27;,\n",
       "                                                                    &#x27;be&#x27;,\n",
       "                                                                    &#x27;because&#x27;,\n",
       "                                                                    &#x27;been&#x27;,\n",
       "                                                                    &#x27;before&#x27;,\n",
       "                                                                    &#x27;being&#x27;,\n",
       "                                                                    &#x27;below&#x27;,\n",
       "                                                                    &#x27;between&#x27;,\n",
       "                                                                    &#x27;both&#x27;,\n",
       "                                                                    &#x27;but&#x27;, &#x27;by&#x27;,\n",
       "                                                                    &#x27;can&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t&quot;, ...})),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LGBMClassifier(random_state=42))]),\n",
       "             param_grid={&#x27;clf__learning_rate&#x27;: [0.01, 0.1, 0.25, 0.5],\n",
       "                         &#x27;clf__n_estimators&#x27;: [100, 500]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words={&#x27;a&#x27;,\n",
       "                                                                    &#x27;about&#x27;,\n",
       "                                                                    &#x27;above&#x27;,\n",
       "                                                                    &#x27;after&#x27;,\n",
       "                                                                    &#x27;again&#x27;,\n",
       "                                                                    &#x27;against&#x27;,\n",
       "                                                                    &#x27;ain&#x27;,\n",
       "                                                                    &#x27;all&#x27;, &#x27;am&#x27;,\n",
       "                                                                    &#x27;an&#x27;, &#x27;and&#x27;,\n",
       "                                                                    &#x27;any&#x27;,\n",
       "                                                                    &#x27;are&#x27;,\n",
       "                                                                    &#x27;aren&#x27;,\n",
       "                                                                    &quot;aren&#x27;t&quot;,\n",
       "                                                                    &#x27;as&#x27;, &#x27;at&#x27;,\n",
       "                                                                    &#x27;be&#x27;,\n",
       "                                                                    &#x27;because&#x27;,\n",
       "                                                                    &#x27;been&#x27;,\n",
       "                                                                    &#x27;before&#x27;,\n",
       "                                                                    &#x27;being&#x27;,\n",
       "                                                                    &#x27;below&#x27;,\n",
       "                                                                    &#x27;between&#x27;,\n",
       "                                                                    &#x27;both&#x27;,\n",
       "                                                                    &#x27;but&#x27;, &#x27;by&#x27;,\n",
       "                                                                    &#x27;can&#x27;,\n",
       "                                                                    &#x27;couldn&#x27;,\n",
       "                                                                    &quot;couldn&#x27;t&quot;, ...})),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LGBMClassifier(random_state=42))]),\n",
       "             param_grid={&#x27;clf__learning_rate&#x27;: [0.01, 0.1, 0.25, 0.5],\n",
       "                         &#x27;clf__n_estimators&#x27;: [100, 500]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                 TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;,\n",
       "                                             &#x27;again&#x27;, &#x27;against&#x27;, &#x27;ain&#x27;, &#x27;all&#x27;,\n",
       "                                             &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                                             &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;,\n",
       "                                             &#x27;because&#x27;, &#x27;been&#x27;, &#x27;before&#x27;,\n",
       "                                             &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                                             &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;,\n",
       "                                             &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})),\n",
       "                (&#x27;clf&#x27;, LGBMClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words={&#x27;a&#x27;, &#x27;about&#x27;, &#x27;above&#x27;, &#x27;after&#x27;, &#x27;again&#x27;, &#x27;against&#x27;,\n",
       "                            &#x27;ain&#x27;, &#x27;all&#x27;, &#x27;am&#x27;, &#x27;an&#x27;, &#x27;and&#x27;, &#x27;any&#x27;, &#x27;are&#x27;,\n",
       "                            &#x27;aren&#x27;, &quot;aren&#x27;t&quot;, &#x27;as&#x27;, &#x27;at&#x27;, &#x27;be&#x27;, &#x27;because&#x27;,\n",
       "                            &#x27;been&#x27;, &#x27;before&#x27;, &#x27;being&#x27;, &#x27;below&#x27;, &#x27;between&#x27;,\n",
       "                            &#x27;both&#x27;, &#x27;but&#x27;, &#x27;by&#x27;, &#x27;can&#x27;, &#x27;couldn&#x27;, &quot;couldn&#x27;t&quot;, ...})</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words={'a',\n",
       "                                                                    'about',\n",
       "                                                                    'above',\n",
       "                                                                    'after',\n",
       "                                                                    'again',\n",
       "                                                                    'against',\n",
       "                                                                    'ain',\n",
       "                                                                    'all', 'am',\n",
       "                                                                    'an', 'and',\n",
       "                                                                    'any',\n",
       "                                                                    'are',\n",
       "                                                                    'aren',\n",
       "                                                                    \"aren't\",\n",
       "                                                                    'as', 'at',\n",
       "                                                                    'be',\n",
       "                                                                    'because',\n",
       "                                                                    'been',\n",
       "                                                                    'before',\n",
       "                                                                    'being',\n",
       "                                                                    'below',\n",
       "                                                                    'between',\n",
       "                                                                    'both',\n",
       "                                                                    'but', 'by',\n",
       "                                                                    'can',\n",
       "                                                                    'couldn',\n",
       "                                                                    \"couldn't\", ...})),\n",
       "                                       ('clf',\n",
       "                                        LGBMClassifier(random_state=42))]),\n",
       "             param_grid={'clf__learning_rate': [0.01, 0.1, 0.25, 0.5],\n",
       "                         'clf__n_estimators': [100, 500]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords)),\n",
    "    ('clf', model_LGBM)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'clf__n_estimators':[100,500],\n",
    "    'clf__learning_rate':[0.01, 0.1, 0.25, 0.5]\n",
    "}\n",
    "\n",
    "grid_LGBM = GridSearchCV(pipe, param_grid = params, scoring='f1', cv=cv)\n",
    "grid_LGBM.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'am', 'an', 'and', 'any', 'are',\n",
      "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', 'been', 'before',\n",
      "                                             'being', 'below', 'between',\n",
      "                                             'both', 'but', 'by', 'can',\n",
      "                                             'couldn', \"couldn't\", ...})),\n",
      "                ('clf', LGBMClassifier(n_estimators=500, random_state=42))])\n",
      "0.77162729415369\n"
     ]
    }
   ],
   "source": [
    "print(grid_LGBM.best_estimator_)\n",
    "print(grid_LGBM.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['LogisticRegression', 'LGBM']\n",
    "scores = [grid_LR.best_score_, grid_LGBM.best_score_]\n",
    "results = pd.DataFrame(index=['cv'], columns=columns)\n",
    "results.loc['cv'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>0.779587</td>\n",
       "      <td>0.771627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LogisticRegression      LGBM\n",
       "cv           0.779587  0.771627"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обе модели на кросс-валидационных выборках смогли превысить требуемое значение качества, протестируем их на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [grid_LR.best_estimator_, grid_LGBM.best_estimator_]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируем модели на отложенной выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_test = [f1_score(y_test, x.predict(X_test)) for x in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.loc['test'] = scores_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cv</th>\n",
       "      <td>0.779587</td>\n",
       "      <td>0.771627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>0.777309</td>\n",
       "      <td>0.773791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LogisticRegression      LGBM\n",
       "cv             0.779587  0.771627\n",
       "test           0.777309  0.773791"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тестовой выборке вновь обе модели смогли превысить необходимый порог f1-меры, равный 0.75. Отличие в оценке моделей практически минимальное, LogisticRegression: 0.7795, LGBMClassifier: 0.7716.\n",
    "\n",
    "Лучшая модель: LGBMClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте мы построили модель классификации текстов, определяющую токсичный комментарий или нет. Для построения модели нам был предоставлен датасет, содержащий 2 признака:\n",
    "* text - комментарий от пользователя на английском языке, самый длинный комментарий 5000 символов, самый короткий - 5 символов.\n",
    "* target - целевая переменная, метка 0 или 1, характеризующая комментарий как токсичный\n",
    "\n",
    "В самом датасете 159292 строки, нет пропусков, нет дубликатов. Сами комментарии представляют из себя строку, состоящую из предложений или законченных фраз, встречаются так же лишние символы в строках, сокращения, даты, цифры.\n",
    "\n",
    "Мы лемматизировали все комментарии в датасете, очистили их от лишних символов, и обучили модели, используя Tfidf трансформацию признаков. Для обучения моделей и их улучшения мы использовали gridsearchcv, вместе с кросс-валидацией. Обе модели на кросс-валидационных выборках смогли превысить требуемое значение качества, при этом модель логистической регрессии имела более высокую оценку (0.7827), чем модель градиентного бустинга (0.77143).\n",
    "\n",
    "На тестовой выборке вновь обе модели смогли превысить необходимый порог f1-меры, равный 0.75. Отличие в оценке моделей практически минимальное, LogisticRegression: 0.7795, LGBMClassifier: 0.7716.\n",
    "\n",
    "Лучшая модель: LogisticRegression.  \n",
    "Ее параметры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidf',\n",
      "                 TfidfVectorizer(stop_words={'a', 'about', 'above', 'after',\n",
      "                                             'again', 'against', 'ain', 'all',\n",
      "                                             'am', 'an', 'and', 'any', 'are',\n",
      "                                             'aren', \"aren't\", 'as', 'at', 'be',\n",
      "                                             'because', 'been', 'before',\n",
      "                                             'being', 'below', 'between',\n",
      "                                             'both', 'but', 'by', 'can',\n",
      "                                             'couldn', \"couldn't\", ...})),\n",
      "                ('clf', LGBMClassifier(n_estimators=500, random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "print(grid_LGBM.best_estimator_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
